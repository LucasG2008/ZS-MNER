{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Language Data: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "Processing Language Data: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "/Users/lucasgranucci/anaconda3/envs/nlp_rsrch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "variety_languages = [\"en\", \"es\", \"ar\", \"zh\", \"ru\", \"hi\", \"sw\", \"tr\", \"ja\", \"fr\", \"ms\", \"ko\"]\n",
    "\"\"\"\n",
    "Variety Languages:\n",
    "en - English\n",
    "es - Spanish\n",
    "ar - Arabic\n",
    "zh - Chinese\n",
    "ru - Russian \n",
    "hi - Hindi\n",
    "sw - Swahili\n",
    "tr - Turkish\n",
    "ja - Japanese\n",
    "fr - French\n",
    "ms - Malay/Indonesian\n",
    "ko - Korean\n",
    "\"\"\"\n",
    "germanic_romance_langs = [\"af\", \"de\", \"en\", \"es\", \"fr\", \"it\", \"nl\", \"pt\"]\n",
    "\n",
    "complete_langs = [\"af\", \"ar\", \"bg\", \"bn\", \"de\", \"el\", \"en\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fr\", \"he\", \"hi\", \"hu\", \"id\", \"it\", \"ja\", \"jv\", \\\n",
    "                  \"ka\", \"kk\", \"ko\", \"ml\", \"mr\", \"ms\", \"my\", \"nl\", \"pt\", \"ru\", \"sw\", \"ta\", \"te\", \"th\", \"tl\", \"tr\", \"ur\", \"vi\", \"yo\", \"zh\"]\n",
    "\n",
    "from src.data.panx_loader import PANX_dataloader\n",
    "\n",
    "dataloader = PANX_dataloader(langs=[\"en\"], nrows=200)\n",
    "df_train, df_val, df_test = dataloader.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "      <th>ner_tags_str</th>\n",
       "      <th>tokens_str</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[Bruce, Beresford, (, Non-Jew, )]</td>\n",
       "      <td>[1, 2, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>B-PER I-PER O O O</td>\n",
       "      <td>Bruce Beresford ( Non-Jew )</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Prince, Albert, Victor, ,, Duke, of, Clarence...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en]</td>\n",
       "      <td>B-PER I-PER I-PER I-PER I-PER I-PER I-PER I-PE...</td>\n",
       "      <td>Prince Albert Victor , Duke of Clarence and Av...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[Gian, Girolamo, Albani]</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "      <td>B-PER I-PER I-PER</td>\n",
       "      <td>Gian Girolamo Albani</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>[5000-meter, run, –, 14:15.61, (, 2015, )]</td>\n",
       "      <td>[3, 4, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "      <td>B-ORG I-ORG O O O O O</td>\n",
       "      <td>5000-meter run – 14:15.61 ( 2015 )</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>[Jean, Frédéric, Frenet]</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "      <td>B-PER I-PER I-PER</td>\n",
       "      <td>Jean Frédéric Frenet</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[Raymerville, –, Markville, East, ,, Ontario]</td>\n",
       "      <td>[5, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en, en]</td>\n",
       "      <td>B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC</td>\n",
       "      <td>Raymerville – Markville East , Ontario</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>[St, George, 's, ,, University, of, London, (,...</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en]</td>\n",
       "      <td>B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O</td>\n",
       "      <td>St George 's , University of London ( SGUL )</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>['', Space, Heater, (, album, ), '']</td>\n",
       "      <td>[0, 3, 4, 4, 4, 4, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "      <td>O B-ORG I-ORG I-ORG I-ORG I-ORG O</td>\n",
       "      <td>'' Space Heater ( album ) ''</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Durrães, e, Tregosa]</td>\n",
       "      <td>[5, 6, 6]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "      <td>B-LOC I-LOC I-LOC</td>\n",
       "      <td>Durrães e Tregosa</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[Live, at, Sin-é, (, Legacy, Edition, ), '']</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en]</td>\n",
       "      <td>B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O</td>\n",
       "      <td>Live at Sin-é ( Legacy Edition ) ''</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens  \\\n",
       "95                   [Bruce, Beresford, (, Non-Jew, )]   \n",
       "15   [Prince, Albert, Victor, ,, Duke, of, Clarence...   \n",
       "30                            [Gian, Girolamo, Albani]   \n",
       "158         [5000-meter, run, –, 14:15.61, (, 2015, )]   \n",
       "128                           [Jean, Frédéric, Frenet]   \n",
       "..                                                 ...   \n",
       "59       [Raymerville, –, Markville, East, ,, Ontario]   \n",
       "171  [St, George, 's, ,, University, of, London, (,...   \n",
       "131               ['', Space, Heater, (, album, ), '']   \n",
       "17                               [Durrães, e, Tregosa]   \n",
       "72        [Live, at, Sin-é, (, Legacy, Edition, ), '']   \n",
       "\n",
       "                           ner_tags                                     langs  \\\n",
       "95                  [1, 2, 0, 0, 0]                      [en, en, en, en, en]   \n",
       "15      [1, 2, 2, 2, 2, 2, 2, 2, 2]      [en, en, en, en, en, en, en, en, en]   \n",
       "30                        [1, 2, 2]                              [en, en, en]   \n",
       "158           [3, 4, 0, 0, 0, 0, 0]              [en, en, en, en, en, en, en]   \n",
       "128                       [1, 2, 2]                              [en, en, en]   \n",
       "..                              ...                                       ...   \n",
       "59               [5, 6, 6, 6, 6, 6]                  [en, en, en, en, en, en]   \n",
       "171  [3, 4, 4, 4, 4, 4, 4, 0, 0, 0]  [en, en, en, en, en, en, en, en, en, en]   \n",
       "131           [0, 3, 4, 4, 4, 4, 0]              [en, en, en, en, en, en, en]   \n",
       "17                        [5, 6, 6]                              [en, en, en]   \n",
       "72         [3, 4, 4, 4, 4, 4, 4, 0]          [en, en, en, en, en, en, en, en]   \n",
       "\n",
       "                                          ner_tags_str  \\\n",
       "95                                   B-PER I-PER O O O   \n",
       "15   B-PER I-PER I-PER I-PER I-PER I-PER I-PER I-PE...   \n",
       "30                                   B-PER I-PER I-PER   \n",
       "158                              B-ORG I-ORG O O O O O   \n",
       "128                                  B-PER I-PER I-PER   \n",
       "..                                                 ...   \n",
       "59                 B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC   \n",
       "171    B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O O O   \n",
       "131                  O B-ORG I-ORG I-ORG I-ORG I-ORG O   \n",
       "17                                   B-LOC I-LOC I-LOC   \n",
       "72         B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O   \n",
       "\n",
       "                                            tokens_str lang  \n",
       "95                         Bruce Beresford ( Non-Jew )   en  \n",
       "15   Prince Albert Victor , Duke of Clarence and Av...   en  \n",
       "30                                Gian Girolamo Albani   en  \n",
       "158                 5000-meter run – 14:15.61 ( 2015 )   en  \n",
       "128                               Jean Frédéric Frenet   en  \n",
       "..                                                 ...  ...  \n",
       "59              Raymerville – Markville East , Ontario   en  \n",
       "171       St George 's , University of London ( SGUL )   en  \n",
       "131                       '' Space Heater ( album ) ''   en  \n",
       "17                                   Durrães e Tregosa   en  \n",
       "72                 Live at Sin-é ( Legacy Edition ) ''   en  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='lang', ylabel='Count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(df_train, x='lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='lang', ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_rows = df_train['lang'].value_counts().max()\n",
    "\n",
    "# Function to oversample a given language\n",
    "def oversample_language(df, lang, max_rows):\n",
    "    df_lang = df[df['lang'] == lang]\n",
    "    if len(df_lang) < max_rows:\n",
    "        oversampled_lang = df_lang.sample(max_rows, replace=True)\n",
    "    else:\n",
    "        oversampled_lang = df_lang\n",
    "    return oversampled_lang\n",
    "\n",
    "# Get a list of all languages in the dataset\n",
    "languages = df_train['lang'].unique()\n",
    "\n",
    "# Oversample each language\n",
    "oversampled_dfs = [oversample_language(df_train, lang, max_rows) for lang in languages]\n",
    "\n",
    "# Concatenate all oversampled dataframes\n",
    "balanced_df = pd.concat(oversampled_dfs)\n",
    "\n",
    "# Shuffle the resulting dataframe\n",
    "balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "sns.histplot(balanced_df, x='lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i.split() for i in df_train['ner_tags_str'].values.tolist()]\n",
    "\n",
    "unique_labels = set(lbl for seq in labels for lbl in seq)\n",
    "\n",
    "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc_loss(train_acc_history, val_acc_history, train_loss_history, val_loss_history):\n",
    "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 3))\n",
    "\n",
    "  sns.lineplot(x=range(len(train_acc_history)), y=train_acc_history, ax=ax[0], label='Train Accuracy')\n",
    "  sns.lineplot(x=[len(train_acc_history)//len(val_acc_history)*i for i in range(len(val_acc_history))], \n",
    "               y=val_acc_history, \n",
    "               ax=ax[0], \n",
    "               label='Validation Accuracy')\n",
    "  \n",
    "  ax[0].set_title('Accuracy History')\n",
    "\n",
    "  sns.lineplot(x=range(len(train_loss_history)), y=train_loss_history, ax=ax[1], label='Train Loss')\n",
    "  sns.lineplot(x=[len(train_loss_history)//len(val_loss_history)*i for i in range(len(val_loss_history))], \n",
    "               y=val_loss_history, \n",
    "               ax=ax[1], \n",
    "               label='Validation Loss')\n",
    "  \n",
    "  ax[1].set_title('Loss History')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] [Acc: 0.378]:   8%|▊         | 6/80.0 [00:21<04:40,  3.79s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 151\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model_weights\n\u001b[1;32m    150\u001b[0m model \u001b[38;5;241m=\u001b[39m BertModel(\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m best_model_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 79\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, df_train, df_val)\u001b[0m\n\u001b[1;32m     76\u001b[0m train_acc_history\u001b[38;5;241m.\u001b[39mappend((total_acc_train \u001b[38;5;241m/\u001b[39m ((idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) ))\n\u001b[1;32m     77\u001b[0m train_loss_history\u001b[38;5;241m.\u001b[39mappend((total_loss_train \u001b[38;5;241m/\u001b[39m ((idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) ))\n\u001b[0;32m---> 79\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     82\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_num\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] [Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(total_acc_train\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m((idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mBATCH_SIZE))\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_rsrch/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_rsrch/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_rsrch/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.bert_model import BertModel\n",
    "from src.data.data_sequence import DataSequence\n",
    "\n",
    "LEARNING_RATE = 3e-3\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "def train_loop(model, df_train, df_val):\n",
    "    train_dataset = DataSequence(df_train, tokenizer)\n",
    "    val_dataset = DataSequence(df_val, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, num_workers=0, batch_size=BATCH_SIZE)\n",
    "    val_dataloader = DataLoader(val_dataset, num_workers=0, batch_size=BATCH_SIZE)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    use_mps = torch.backends.mps.is_available()\n",
    "\n",
    "    use_mps = False\n",
    "    \n",
    "    device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    if use_mps:\n",
    "        model.to(device)\n",
    "    elif use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    print(f\"Running on: {device}\")\n",
    "\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    #Initialize Variables for EarlyStopping\n",
    "    best_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "    patience = 2\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        pbar = tqdm(total=len(df_train)/BATCH_SIZE, desc=f\"[Epoch: {epoch_num + 1}] [Acc: {0}]\")\n",
    "        for idx, batch_data in enumerate(train_dataloader):\n",
    "            train_data, train_label = batch_data\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss, logits = model(input_id, mask, train_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "                logits_clean = logits[i][train_label[i] != -100]\n",
    "                label_clean = train_label[i][train_label[i] != -100]\n",
    "\n",
    "                predictions = logits_clean.argmax(dim=1)\n",
    "                acc = (predictions == label_clean).float().mean()\n",
    "                total_acc_train += acc\n",
    "                total_loss_train += loss.item()\n",
    "\n",
    "            train_acc_history.append((total_acc_train / ((idx+1)*2) ))\n",
    "            train_loss_history.append((total_loss_train / ((idx+1)*2) ))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description(f\"[Epoch: {epoch_num + 1}] [Acc: {(total_acc_train / ((idx + 1) * BATCH_SIZE)):.3f}]\")\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(total=len(df_val)/BATCH_SIZE, desc=f\"[Validation Acc: {0}]\")\n",
    "            for idx, batch_data in enumerate(val_dataloader):\n",
    "                val_data, val_label = batch_data\n",
    "    \n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_data['attention_mask'].squeeze(1).to(device)\n",
    "                input_id = val_data['input_ids'].squeeze(1).to(device)\n",
    "    \n",
    "                loss, logits = model(input_id, mask, val_label)\n",
    "    \n",
    "                for i in range(logits.shape[0]):\n",
    "                    logits_clean = logits[i][val_label[i] != -100]\n",
    "                    label_clean = val_label[i][val_label[i] != -100]\n",
    "    \n",
    "                    predictions = logits_clean.argmax(dim=1)\n",
    "                    acc = (predictions == label_clean).float().mean()\n",
    "                    total_acc_val += acc\n",
    "                    total_loss_val += loss.item()\n",
    "    \n",
    "                val_acc_history.append((total_acc_val / ((idx+1)*2) ))\n",
    "                val_loss_history.append((total_loss_val / ((idx+1)*2) ))\n",
    "\n",
    "                pbar.set_description(f\"[Validation Acc: {(total_acc_val / ((idx + 1) * BATCH_SIZE)):.3f}]\")\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        val_accuracy = total_acc_val / len(df_val)\n",
    "        val_loss = total_loss_val / len(df_val)\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num+1} \\\n",
    "            | Loss: {total_loss_train / len(df_train): .3f} \\\n",
    "            | Accuracy: {total_acc_train / len(df_train): .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(df_val): .3f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(df_val): .3f}' \\\n",
    "        )\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())  # Deep copy here      \n",
    "            patience = 2  # Reset patience counter\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print('Early Stopping Triggered')\n",
    "                break\n",
    "    \n",
    "    train_acc_history = [tensor.item() if isinstance(tensor, torch.Tensor) else tensor for tensor in train_acc_history]\n",
    "    train_loss_history = [tensor.item() if isinstance(tensor, torch.Tensor) else tensor for tensor in train_loss_history]\n",
    "\n",
    "    val_acc_history = [tensor.item() if isinstance(tensor, torch.Tensor) else tensor for tensor in val_acc_history]\n",
    "    val_loss_history = [tensor.item() if isinstance(tensor, torch.Tensor) else tensor for tensor in val_loss_history]\n",
    "\n",
    "    plot_acc_loss(train_acc_history, val_acc_history, train_loss_history, val_loss_history)\n",
    "\n",
    "    return best_model_weights\n",
    "\n",
    "model = BertModel(7)\n",
    "best_model_weights = train_loop(model, df_train, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'models/var_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aaf90f2faef4e15a18314bfeb07d44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Test Accuracy: 0]:   0%|          | 0/5800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.898\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, df_test):\n",
    "    test_dataset = DataSequence(df_test)\n",
    "    test_dataloader = DataLoader(test_dataset, num_workers=0, batch_size=1)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    use_mps = torch.backends.mps.is_available()\n",
    "    \n",
    "    device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "\n",
    "    if use_mps:\n",
    "        model.to(device)\n",
    "    elif use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    print(f\"Running on: {device}\")\n",
    "\n",
    "    total_acc_test = 0.0\n",
    "\n",
    "    pbar = tqdm(total=len(df_test), desc=f\"[Test Accuracy: {0}]\")\n",
    "    for idx, batch_data in enumerate(test_dataloader):\n",
    "        test_data, test_label = batch_data\n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        mask = test_data['attention_mask'].squeeze(1).to(device)\n",
    "        input_id = test_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        loss, logits = model(input_id, mask, test_label)\n",
    "\n",
    "        for i in range(logits.shape[0]):\n",
    "            logits_clean = logits[i][test_label[i] != -100]\n",
    "            label_clean = test_label[i][test_label[i] != -100]\n",
    "\n",
    "            predictions = logits_clean.argmax(dim=1)\n",
    "            acc = (predictions == label_clean).float().mean()\n",
    "            total_acc_test += acc\n",
    "\n",
    "        pbar.set_description(f\"[Test Accuracy: {(total_acc_test / ((idx + 1))):.3f}]\")\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    val_accuracy = total_acc_test / len(df_test)\n",
    "    print(f'Test Accuracy: {val_accuracy: .3f}')\n",
    "\n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6171becafb49de9fc18e3eff0e279f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Test Accuracy: 0]:   0%|          | 0/5800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.895\n"
     ]
    }
   ],
   "source": [
    "test_model = BertModel()\n",
    "test_model.load_state_dict(best_model_weights)\n",
    "test_model.eval()\n",
    "evaluate(test_model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a8016f1212431d9951660ede2dca97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching Language Data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdeabc11715b4b8aa4cb442a76afb134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Language Data:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasgranucci/anaconda3/envs/nlp_rsrch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001a81959a22477bb9b74cac6a8b6517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Test Accuracy: 0]:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.520\n"
     ]
    }
   ],
   "source": [
    "test_train, test_val, test_test = load_data(langs=['ur'], nrows=1000)\n",
    "evaluate(model, test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_word_ids(texts, label_all_tokens):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(1 if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "    return label_ids\n",
    "\n",
    "def evaluate_one_text(model, sentence):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    use_mps = torch.backends.mps.is_available()\n",
    "    \n",
    "    device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "\n",
    "    if use_mps:\n",
    "        model.to(device)\n",
    "    elif use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    print(f\"Running on: {device}\")\n",
    "\n",
    "    text = tokenizer(sentence, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text['attention_mask'].to(device)\n",
    "    input_id = text['input_ids'].to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence, label_all_tokens=False)).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
    "    print(sentence)\n",
    "    print(prediction_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: mps\n",
      "昨日、 韓国人でいっぱいの船が日本に着きました。 外務省の上川陽子が危機を「もう解けた事態」と呼びました。\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"昨日、 韓国人でいっぱいの船が日本に着きました。 外務省の上川陽子が危機を「もう解けた事態」と呼びました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'models/ger_rom_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (bert): BertForTokenClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_model = BertModel(len(unique_labels))\n",
    "test_model.load_state_dict(torch.load('models/var_model.pth'))\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: mps\n",
      "In 2023, Elon Musk met with executives from Google at their headquarters in Mountain View, California, to discuss advancements in artificial intelligence.\n",
      "['O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(test_model, \"In 2023, Elon Musk met with executives from Google at their headquarters in Mountain View, California, to discuss advancements in artificial intelligence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
